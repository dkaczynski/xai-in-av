\section{Alignment with Autonomous Vehicles}\label{sec:Alignment}

The use cases defined in \ref{sec:UseCases} \textit{Use Cases} span users with a wide variety of backgrounds.  This section will be the innovative contribution of this literature survey.

\subsection{Existing Research}



\begin{itemize}
    \item Textual Explanations for Self-Driving Vehicles \cite{kim2018textual}: This is the most comprehensive paper from this group of authors.  Very great work!  Explanations for the vehicle's decisions are presented to human subjects for validation.

    \item Interpretable Learning for Self-Driving Cars by Visualizing Causal Attention \cite{Kim2017InterpretableLF}:  This paper focuses more on just the visual interpretation of the agent's choices.

    \item Show, Attend, Control, and Justify: Interpretable Learning for Self-Driving Cars \cite{Kim2017ShowA}: This paper describes the LSTM topology for generating textual explanations

    \item Why did my car just do that? Explaining semi-autonomous driving actions to improve driver understanding, trust, and performance \cite{Koo2015}:  Human subjects act as drivers in HIL simulation of a semi-autonomous vehicle that can create hard brake events in emergency scenarios.
    
    \item Explaining How a Deep Neural Network Trained with End-to-End Learning Steers a Car \cite{Bojarski2017ExplainingHA}: There's one more article by these authors (currently in our Mendeley)...one is short and visual, the other is highly theoretical and explains in detail the process for generating saliency maps
\end{itemize}

\subsection{Gaps and Method Alignment}



